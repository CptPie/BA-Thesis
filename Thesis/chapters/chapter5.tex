\chapter{Implementation of a JIT compiler for Smalltalk-80}\label{cha:impls}
In this chapter, I will describe the design decisions and implementation details of this (partial) \jit{} compiler implementation for Smalltalk-80. 
Both the used interpreter implementations and the problems encountered while working with them will be discussed and explained.

\section{Design}
The fundamental design aspects follow closely the general design for a \jit{} compiler outlined in \Cref{cha:jit}.
Since both of the used interpreter implementations follow the description provided by the Bluebook, both the interpreter and the changes to facilitate \jit{} compilation are very similar. 

To recap the high-level structure again. Utilizing the interpretation cycle of the baseline implementations, every time an instruction is executed, the instruction is added alongside some metadata to the currently active \bb{}. If the instruction is considered to be of a type that produces a jump in the program flow (a branching instruction), the \bb{} is ended, and a new \bb{} is created. This relationship between instructions and \bbs{} is illustrated in \Cref{fig:basicblock-1}. 

\image[h]{\textwidth}{basicblock-1}{Illustration of the actions done on a \bb{} based on the instruction.}{basicblock-1}

When creating a new \bb{}, the location of the next instruction, so the target of the jump in the program flow, is used as a unique identifier for the \bb{}. 
If a jump to an existing \bb{} is detected, its heat value is incremented by one and no instructions are added to the block. 
Once a block hits the configured heat threshold value, it is compiled to machine bytecode. On the contrary, if a \bb{} has not been executed for a certain number of cycles, the heat value gets decremented. This resolves the issue of unnecessarily compiling rarely executed \bbs{}. 
Following the management of the heat value, the compilation of the \bb{} is initiated.

Translating the instruction to machine bytecode is a somewhat manual process, at least initially. There are two ways to do this translation: translating the logic of an instruction directly into machine bytecode or through an intermediate language. For this project it was chosen to go with the intermediate language approach, namely reimplementing the logic using the riscv64 assembly language. For the translation between the assembly and the bytecode, the library keystone (\url{https://www.keystone-engine.org/}) is used.

After translating, the interpreter loop continues as before, with one exception. When a \bb{}, which has already been translated to bytecode, is entered, instead of entering either the interpretation or the compilation steps, the program jumps directly to the previously generated bytecode and executes it. All the variables affected need to be read from and written back to the memory directly to notify the interpreter of any changes.

\section{New classes and data structures}
Several new classes and data structures were defined independently of the existing codebase to manage information necessary for the compilation process. This modular approach already proved vital during the project when switching from one interpreter implementation to the other. This section will give a brief summary of the purpose of each of these additions and the reasoning behind certain aspects.

\paragraph{The JIT class}
On startup, variables necessary for the functionality of the interpreter are initialized by calling a function. Since this function is only executed once, on startup, this is also well suited to set up the necessary variables for the \jit{} compiler. 
For this, a new class, called JIT, was created. The purpose of this class is to bundle all functionalities related to the JIT process in itself and provide scoping for the variables used. Its constructor is used to initialize the aforementioned variables. The only configurable variable for the \jit{} compiler is the heat threshold, that is, how often a \bb{} has to be executed to be eligible for compilation. This value is passed to the class by the constructor.
This class keeps track of all identified \bbs{}, the configured heat level, and the \bb{} that contains the currently interpreted instruction.
Since this class manages the majority of the logic for the JIT compiler, most newly created functions are members of this class. 

\paragraph{The Location structure}
As explained before in \Cref{cha:smalltalk}, the interpreted language does not have a concept of files. Every piece of source code is kept in memory, separated by context. 
The Location structure was created to keep track of a position within the program. This structure saves the currently active context, the method context, and the instruction pointer within those

\paragraph{The Instruction structure}
The purpose of this structure is to represent a single instruction in the program. 
Each instruction contains information about where in the program flow it is located, its location value, the bytecode it represents, and a human-readable name for the instruction to ease debugging.

\paragraph{The BasicBlock structure}
To manage the \bbs{} properly, this structure was introduced.
The primary purpose of the \bb{} is to keep a list of instructions within it, as well as the block's heat value and its start and end locations. 
The instruction list is necessary for the translation to machine bytecode as every instruction is translated individually. After translating the instruction, the resulting bytecode is added to the Basic Block's bytecode variable for later use. 
Keeping track of the beginning of a \bb{} is necessary since this information is used to find the correct \bb{} to jump to, or if none exists, to create a new \bb{}.

\section{Dan Banays Smalltalk Interpreter}
After explaining the basic structure and ideas of the structure envisioned for the \jit{} compiler, we can now talk about the actual implementations done for this project. As mentioned before in section \Cref{cha:riscV} the implementation of a Smalltalk interpreter by Dan Banay \cite{dbanayST} was the basis for this project's idea.
\subsection{Structure and Design}
This implementation, written in C++, closely follows the design described by the Bluebook. The SDL2 framework is utilized for the graphical interface.
The codebase is distributed among several files, but \texttt{interpreter.cpp} and \texttt{interpreter.h} are containing most of the relevant logic. Functions are dispersed between the header file and the source file without any apparent reason, making reading through the codebase quite cumbersome. 

The entry point of the interpreter is \texttt{Interpreter::init()}, which is the initialization function described in \Cref{cha:smalltalk}. Following the initialization, the interpretation loop is entered through a call to \texttt{Interpreter::run()}, which in turn calls \texttt{Interpreter::cycle()} within an infinite loop. One notable aspect here is that the interpreter enforces a strict limit to the cycles executed per second. This is enforced within the \texttt{run()} functions infinite loop by keeping a running total of the cycles executed during the second (see \texttt{Project/banay-Smalltalk/src/main.cpp} lines 848 to 866). 

Entering the \texttt{cycle()} function, the implementation practically mirrors the Bluebook's description, even having the Smalltalk-80 source commented inside the function and the C++ implementation below. 

One other notable detail about this implementation concerns the memory model. This part is purposefully left out of the Bluebook description as this depends on the underlying machine hosting the virtual machine. Banay chose to represent the segmented memory as a two-dimensional array of 16-bit integers. The first dimension is the amount of segments while the second dimension represents the size per segment. This implementation has 16 segments with a size of 65536 16-bit words. The specifics of accessing the memory values are abstracted away by multiple levels of abstraction and nested function calls. 

\subsection{Changes to the interpreter}
As described at the beginning of this chapter, the first changes already appear within the initialization function where the constructor to the JIT class is called, and the initial \bb{} is created. For testing purposes, all the \jit{} compiler functionalities were put behind a compile flag called \texttt{JIT\_Enabled}. 

The next changes were done to \texttt{Interpreter::dispatchOnThisBytecode()}, the dispatch function for instructions. As this function is called for every instruction that gets identified, this is a suitable location to add the instruction to the current \bb{}. As long as the \bb{} has not been ended previously (by branching), the instruction is added to the \bbs{} instruction list. Otherwise, this step is ignored. After this distinction, the interpreter's logic continues as normal. 

There is a valid argument to be made to implement the \bb{} ending logic in this function as well, but I decided against this since, at this point of the interpretation process, we do not yet know the location of the branch target. As such, the decision was taken to delay the ending of the \bbs{} to a point in execution where the target is already getting calculated by the interpreter logic, and we can just reuse the value for this purpose. 

Continuing from the dispatch function, we follow the interpreter logic to jump instructions, the easiest of the three breaking instruction types.
Every jump instruction eventually ends up at a single interpreter function called \texttt{jump()}, which modifies the instruction pointer and thereby implements a simple jump.
The target for the jump is trivially calculated by adding the given offset to the current instruction pointer. Therefore, we can trivially use this value to end our \bb{} by calling \texttt{JIT::endBasicBlock()} with the current code location (retrieved by using the helper function \texttt{currentLocation()}) and the jump target, which is calculated as explained. 

Similarly, once we know the branch targets for the remaining two types, the send and return instructions, we can finish up the \bbs{} in the same manner.

Inside \texttt{JIT::endBasicBlock()}, the end Location, the next Location and the hasEnded boolean are set. Utilizing the next location, passed as a function argument, the next \bb{} is created and set as the active \bb{}. With this, the branch is entirely processed by the \jit{} compiler. 

The final change to take a look at, is the prototype for the compilation of an instruction. For this, the addition functionality, implemented in the function \texttt{primitiveAdd()}, was selected. What appeared to be an rather easy functionality to implement in RISC-V assembly turned out to be much more complex than first envisioned. 
In concept, the function is quite simple, it retrieves two arguments from the stack, the receiver pointer and the argument pointer, resolves the pointers to retrieve the values, performs the addition and pushes the result on the stack. 
Simply retrieving the values was already more complex than imagined, as the \texttt{popInteger()} functions also verify the type of the value on top of the stack.
This resulted in a decision to either implement this verification in assembly or ignore the checks and assume in good faith that the values on the stack are integers.
After further investigation, it turned out that the integer check boils down to a check of the lowest bit being 1. This finding made the decision choose the safe option and implement the check in assembly quite easy. 
The prototype assembly code for the \texttt{primitiveAdd()} functionality can be found in \Cref{lst:primitiveAddAsm}.
\begin{listing}[h]
\begin{minted}{ASM}
li t0, 1;
li t1, {topOfStack};
andi t3, t1, 1;        // check for the integer object class bit 
                       //(lowest bit = 1 -> integer object)
bne t3, t0, end;       // jump to end if it is NOT an integer object
srli t1, t1, 1;        // remove the lowest bit to retrieve the value
li t2, {topOfStack-1};
andi t3, t2, 1;        // integer object check for the second integer
bne t3, t0, end;       // jump to end if it is NOT an integer object
srli t2, t2, 1;        // remove the lowest bit to retrieve the value
add t1, t1, t2;        // perform the addition
sh t1, {topOfStack-1}; // write the result back to the new stack top
end: 
\end{minted}
\caption{Prototyped assembly code for the \texttt{primitiveAdd()} function.}
\label{lst:primitiveAddAsm}
\end{listing}

\subsection{Encountered Problems}
Having discussed the prototype implementation of the compilation process, we can now address the issues that arose during the development.
The primary issue directly results from the segmented memory approach chosen in this interpreter implementation. 
To resolve the indexes for the memory array, it is necessary to jump through several functions. Since this is not feasible for the assembly implementation, a calculation \enquote{by hand} is necessary. 
I replicated the calculations done within the nested functions as a simple addition of values, removing the nesting from the equation and ending up with values being added to each other.
Comparing the memory values pointed to by the calculations to the values retrieved by using the interpreter's functions did not result in the same values. 
After checking the calculations again, with no apparent mistakes found, I went on to dump the memory around the calculated values to the terminal output to manually verify how far the calculations were off. This again did not result in much insight, as nothing resembling the stack could be found.
Finally, I wrote the contents of the whole memory array to a file and began looking for the location of the stack. This also did not end up being helpful since while the stack was found, the address needed to be more consistent between runs of the same state while the calculated values remained the same.
The static calculations I reverse-engineered from the function call contain some kind of mistake, but after several attempts and a lot of time spent on the issue, I was unable to identify the problem.

As hinted at before, the structure of the codebase is not trivial to understand. This is due to the questionable split of function implementations between the header and the source files. While this can be dealt with, it results in a lot of unnecessary jumping back and forth between files.

\section{Keller's Smalltalk-80 Interpreter}
The second interpreter implementation being used is the Smalltalk-80 interpreter developed by Rochus Keller \cite{Keller2021}. The thought behind switching to this implementation was to avoid the issues mentioned above. 

\subsection{Structure and Design}
Similarly to the approach by Banay, it is also a really closely based on the description provided in the Bluebook. 
Due to this similarity, the interpreter's aspects that basically mirror the previously discussed implementation will be skipped over, and only the notable differences will be pointed out. 

This implementation utilizes the QT framework for the graphical user interface. This also necessitates a bunch of detail changes in the interpreter's codebase, mainly concerning data types. Instead of standard data types like the standard integers of C and C++, this implementation utilizes the QT native counterparts. This does not result in much of a change when considering the implementation of the \jit{} compiler but is still worth noting. 
An other aspect of using the QT framework is the necessity of using the framework's internal logging interface to print output to the console. 

The other main difference to Banay's implementation is how the memory model is structured. Instead of the segmented memory approach, the implementation by Keller uses an object-oriented approach where the main class called \texttt{ObjectMemory2} maintains a table of slot objects, which in turn contains an array of bytes. 
While this memory structure seems more complex, the hope was that the memory operations' referencing and debugging would become more accessible with the explicit objects.

\subsection{Changes to the interpreter}
The changes to the interpreter are equivalent to the previous implementation. The only notable difference lies within the better separation between the JIT code and the interpreter codebase. This is due to the more explicit separation of Keller's codebase prior to the addition of the \jit{} compiler as well as the lessons learned from the work done on Banays interpreter. Furthermore, many changes done in the previously used implementation were not added to this part of the project simply due to the time constraints of this thesis.

\subsection{Encountered Problems}
Regrettably, switching to Keller's interpreter did not result in flawless development either. While the codebase is much easier to read through due to a clearer separation between header and source files, using the QT framework requires some overhead in programming that adds a lot of unnecessary coupling. 

Additionally, the main issue encountered while working on this implementation was unexpected. QT as a framework provides a lot of functionality to the programmer, from graphical aspects like drawing and designing windows, handling input and output behaviours and providing logging functions. This last aspect, the logging, has one small but annoying drawback. It completely disables printing to a console without going through the specific functions provided by the framework. This does not seem too bad at first glance, but this, combined with my unfamiliarity with the framework as a whole resulted in being completely unable to log information to the console. To use the logging functions from QT, one needs to import the bindings to the source file that calls the functions. The problem lies within this binding import. When trying to import the QT bindings, the compiler was never able to resolve the reference when attempting to add the logging functionalities to the JIT class. It may have been an issue with the generated Makefile not setting a required compiler and linker flags or something else entirely, but the result is all the same. The inability to log any information made verifying the functionality of the \jit{} compiler a tedious task. Of course, the usage of gdb still worked fine, but this does not replace the quick output of information for several instructions, \bbs{} and so on at a glance. 

This inability to log information also made understanding this implementation's memory model quite a bit harder.
As mentioned in the section about Banays implementation, understanding the memory model is required in order to implement the Smalltalk-80 instructions in riscv64 assembly.
As of writing this, I needed more time to understand this memory model fully. 
As mentioned above, the memory is modelled through a sequence of objects, managing lists of objects which in turn manage the actual memory.
In retrospect, this structure is not much of an improvement compared to the implementation by Banay.
