\chapter{Implementation of a JIT compiler for Smalltalk-80}
In this chapter I will describe the design decisions and implementation details of this (partial) \jit{} compiler implementation for Smalltalk-80. Both of the used interpreter implementations as well as the problems encountered while working with them will be discussed and explained.  

\section{Design}
The fundamental design aspects follow closely the general design for a \jit{} compiler outlined in \Cref{cha:jit}.
Since both of the used interpreter implementations follow the description provided by the Bluebook, both the interpreter and the changes to facilitate \jit{} compilation are very similar. 

To recap the high-level structure again. Utilizing the interpretation cycle of the baseline implementations, every time a instruction is executed, the instruction is added alongside some metadata to the currently active \bb{}. If the instruction is considered to be of a type that produces a jump in the program flow (a branching instruction), the \bb{} is ended and a new \bb{} is created. This relationship between instructions and \bbs{} is illustrated in \Cref{fig:basicblock-1}. 

\image[h]{\textwidth}{basicblock-1}{Illustration of the actions done on a \bb{} based on the instruction.}{basicblock-1}

When creating a new \bb{}, the location of the next instruction, so the target of the jump in the program flow, is used as an unique identifier for the \bb{}. 
If a jump to an existing \bb{} is detected, its heat value is incremented by one and no instructions are added to the block. 
Once a block hits the configured heat threshold value, it is compiled to machine bytecode. In contrary, if a \bb{} has not been executed for a certain amount of cycles, the heat value gets decremented. This resolves the issue of unnecessarily compiling rarely executed \bbs{}. 
Following the management of the heat value, the compilation of the \bb{} is initiated.

The actual translation of the instruction to machine bytecode is a rather manual process. There are two ways to do this translation, either by translating the logic of an instruction directly into machine bytecode or by going through an intermediate language. For this project it was chosen to go with the intermediate language approach, namely reimplementing the logic using the riscv64 assembly language. For the translation between the assembly and the bytecode the library keystone (\url{https://www.keystone-engine.org/}) is used.

After translating the interpreter loop continues as before with one exception. When a \bb{}, which has already been translated to bytecode is entered, instead of entering either the interpretation or the compilation steps, the program instead jumps directly to the previously generated bytecode and executes it. All the variables effected need to be read from and written back to the memory directly to notify the interpreter of any changes.

\section{New classes and data structures}
For the management of information necessary for the compilation process several new classes and data structures were defined independently of the existing codebase. This modular approach already proved vital during the project when switching from one interpreter implementation to the other. A brief summary of the purpose of each of these additions along with the reasoning behind certain aspects will be given in this section.

\subsection{The JIT class}
On startup, variables necessary for the functionality of the interpreter are initialized by calling a function. Since this function is only executed once, on startup, this is also well suited to setup the necessary variables for the \jit{} compiler. 
For this a new class, called JIT, was created. The purpose of this class is to bundle all functionalities related to the JIT process in itself and provide scoping for the variables used. It's constructor is used to do the aforementioned initialization of variables. The only configurable variable for the \jit{} compiler is the heat threshold, that is how often a \bb{} has to be executed to be eligible for compilation. This value is passed to the class by the constructor.
This class keeps track of all identified \bbs{}, the configured heat level as well as the \bb{} that contains the currently interpreted instruction.
Since this class manages the majority of the logic for the JIT compiler, most newly created functions are members of this class. 

\subsection{The location structure}
As explained before in \Cref{cha:smalltalk}, the interpreted language does not really have a concept of files. Every piece of source code is kept in memory, separated by contexts. 
To keep track of a position within the program, the Location structure was created. This structure saves the currently active context, the method context and the instruction pointer within those.

\subsection{The Instruction structure}
The purpose of this structure is to represent a single instruction in the program. Every instructions contains information about where in the program flow it is located, its location value as well as the bytecode it represents and a human readable name for the instruction to ease debugging.

\subsection{The BasicBlock structure}
To manage the \bbs{} properly, this structure got introduced.
The primary purpose of the \bb{} is to keep a list of instructions within it, as well as the blocks heat value and its start and end locations. 
The instruction list is necessary for the translation to machine bytecode as every instruction is translated individually. After translating the instruction, the resulting bytecode will get added to the Basic Block's bytecode variable for later use. 
Keeping track of the beginning of a \bb{} is necessary since this information is used to find the correct \bb{} to jump to, or if none exist, to create a new \bb{}.

\section{Dan Banays Smalltalk Interpreter}
After explaining the basic structure and ideas of the structure envisioned for the \jit{} compiler, we can now talk about the actual implementations done for this project. As mentioned before in section \Cref{cha:riscV} the implementation of a Smalltalk interpreter by Dan Banay \cite{dbanayST} was the basis for this project's idea.
\subsection{Structure and Design}
This implementation follows closely the design described by the Bluebook, and was written in C++. For the graphical interface, the SDL2 framework is utilized. 
The codebase is distributed among several files but, \texttt{interpreter.cpp} and \texttt{interpreter.h} are containing most of the relevant logic. Functions are dispersed between the header file and the source file without any apparent reason, which makes reading through the codebase quite cumbersome. 

The entry point of the interpreter is \texttt{Interpreter::init()} which is the initialization function described in \Cref{cha:smalltalk}. Following the initialization the interpretation loop is entered through a call to \texttt{Interpreter::run()} which in turn calls \texttt{Interpreter::cycle()} within an infinite loop. One notable aspect here is that the interpreter enforces a strict limit to the cycles executed per second. This is enforced within the \texttt{run()} functions infinite loop by keeping a running total of the cycles executed during the second (see \texttt{Project/Smalltalk/src/main.cpp} lines 848 to 866). 

Entering the \texttt{cycle()} function, the implementation practically mirrors the Bluebook's description, even having the Smalltalk-80 source commented inside the function and the C++ implementation below. 

One other notable detail about this implementation concerns the memory model. This part is purposefully left out of the Bluebook description as this depends on the underlying machine hosting the virtual machine. Banay chose to represent the segmented memory as a two dimensional array of 16 bit integers. The first dimension is the amount of segments while the second dimension represents the size per segment. In this implementation there are 16 segments with a size of 65536 16 bit words. The specifics of accessing the memory values are abstracted away by multiple levels of abstraction and nested function calls. 

\subsection{Changes to the interpreter}
As described at the beginning of this chapter, the first changes already appear within the initialization function where the constructor to the JIT class is called and the initial \bb{} is created. For testing purposes, all the \jit{} compiler functionalities were put behind a compile flag called \texttt{JIT\_Enabled}. 

The next changes were done to \texttt{Interpreter::dispatchOnThisBytecode()}, the dispatch function for instructions. As this is the function is called for every instruction that gets identified, this is a suitable location to add the instruction to the current \bb{}. As long as the \bb{} has not been ended previously (by branching), the instruction is added to the \bbs{} instruction list, otherwise this step is getting ignored. There after the interpreter logic continues normally. 

There is a valid argument to be made to implement the \bb{} ending logic in this function as well, but I decided against this, since at this point of the interpretation process, we do not yet know the location of the branch target. As such the decision was taken to delay the ending of the \bbs{} to a point in execution where the target is already getting calculated by the interpreter logic and we can just reuse the value for this purpose. 

Continuing on from the dispatch function, we follow the interpreter logic to the easiest of the 3 breaking instruction types, the jump instructions. Every jump instruction eventually ends up at a single interpreter function called \texttt{jump()} which handles the modification of the instruction pointer and thereby implementing a simple jump.
The target for the jump is trivially calculated by adding the given offset to the current instruction pointer. Therefore we can trivially use this value to end our \bb{} by calling \texttt{JIT::endBasicBlock()} with the current code location (retrieved by using the helper function \texttt{currentLocation()}) and the next location, which is calculated as explained. 

Similarly, once we know the targets of the branch for the remaining two types, the send and return instructions, we can finish up the \bbs{} in the same manner.

Inside \texttt{JIT::endBasicBlock()} the end Location, the next Location and the hasEnded boolean are set. Utilizing the next location, which got passed as an argument, the next \bb{} is created and set as the active \bb{}. With this the branch is completely processed by the JIT compiler. 

The final change to take a look at, is the prototype for the compilation of an instruction. For this the addition functionality was selected. What appeared to be an rather easy functionality to implement in RISC-V assembly turned out to be much more complex than first envisioned. 
In concept, the function is quite simple, it retrieves two arguments from the stack, the receiver pointer and the argument pointer, resolves the pointers to retrieve the values, performs the addition and pushes the result on the stack. 
Simply retrieving the values was already more complex than imagined, as the \texttt{popInteger()} functions also verify the type of the value on top of the stack. This resulted in a decision, either implementing this check in assembly as well, or ignoring the checks and assuming in good faith that the values on the stack are actually integers. After further investigation it turned out that the integer check basically boils down to a check of the lowest bit being 1. This finding made the decision to go for with the safe option and implement the check in assembly quite easy. 
The prototype assembly code for the \texttt{primitiveAdd()} functionality can be found in \Cref{lst:primitiveAddAsm}.
\begin{listing}[h]
\begin{minted}{ASM}
li t0, 1;
li t1, {topOfStack};
andi t3, t1, 1;        // check for the integer object class bit 
                       //(lowest bit = 1 -> integer object)
bne t3, t0, end;       // jump to end if it is NOT an integer object
srli t1, t1, 1;        // remove the lowest bit to retrieve the value
li t2, {topOfStack-1};
andi t3, t2, 1;        // integer object check for the second integer
bne t3, t0, end;       // jump to end if it is NOT an integer object
srli t2, t2, 1;        // remove the lowest bit to retrieve the value
add t1, t1, t2;        // perform the addition
sh t1, {topOfStack-1}; // write the result back to the new stack top
end: 
\end{minted}
\caption{Prototyped assembly code for the \texttt{primitiveAdd()} function.}
\label{lst:primitiveAddAsm}
\end{listing}

\subsection{Encountered Problems}
Having discussed the prototype implementation of the compilation process now enables the discussion of the problems discovered during the development. 
The primary issue is a direct result of the segmented memory approach chosen in this interpreter implementation. 
To resolve the indexes for the memory array it is necessary to jump through several functions. Since this is not feasible for the assembly implementation, a calculation \enquote{by hand} is necessary. 
I tried to replicate the calculations done within the nested functions as a simple addition of values, basically removing the nesting from the equation and ending up with values being added to each other. 
Comparing the memory values pointed to by the calculations to the values retrieved by usage of the functions of the interpreter did not result in the same values. 
After checking the calculations again, with no apparent mistakes found, I went on to just dump the memory around the calculated values to the output to manually verify how far the calculations are off. This again did not result in much insight as nothing appearing to be resembling the stack could be found.
Finally I wrote the contents of the whole memory array to a file and began looking for the location of the stack. This also did not end up being helpful since while the stack was found, the address was not consistent between runs of the same state while the calculated values remained the same.
Obviously there is some kind of mistake within the static calculations I reverse engineered from the function call, but after several attempts and a lot of time spend on the issue, I was unable to identify the problem.

An other issue was already hinted at before, the structure of the codebase is not trivial to understand. This is due to the questionable split of function implementations between the header and the source files. While this can be dealt with, it resulted in a lot of unnecessary jumping back and forth between files. 

\section{Keller's Smalltalk-80 Interpreter}
The second interpreter implementation being used is the Smalltalk-80 interpreter developed by Rochus Keller \cite{Keller2021}. The thought behind switching to this implementation was to avoid the aforementioned issues. 

\subsection{Structure and Design}
Similarly to the approach by Banay, it is also a really closely based on the description provided in the Bluebook. 
Due to this similarity, the aspects of the interpreter that basically mirror the previously discussed implementation will be skipped over and only the notable differences will be pointed out. 

For one, this implementation utilizes the QT framework for the graphical user interface. This also necessitates a bunch of detail changes in the interpreters codebase, mainly concerning data types. Instead of standard data types like the standard integers of C and C++ this implementation utilizes the QT native counterparts. This does not result in much of a change when considering the implementation of the \jit{} compiler but is still worth noting. 
An other aspect resulting from the usage of the QT framework is the necessity to use the frameworks internal logging interface to print output to the console. 

The other main difference to Banays implementation is how the memory model is structured. Instead of the segmented memory approach, the implementation by Keller uses an object oriented approach where the main class called \texttt{ObjectMemory2} maintains a table of slot objects, which in turn contains an array of bytes. While this memory structure seems more complex, the hope was that with the explicit objects, the referencing and debugging of the memory operations becomes easier. 

\subsection{Changes to the interpreter}
The changes to the interpreter are basically equivalent to the previous implementation. The only notable difference lies within the better separation between the JIT code and the interpreter codebase. This is due to the clearer separation of Kellers codebase prior to the addition of the \jit{} compiler as well as the lessons learned from the work done on Banays interpreter. 

\subsection{Encountered Problems}
\todo{write}
